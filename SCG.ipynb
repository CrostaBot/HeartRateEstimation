{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HEART RATE ESTIMATION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction:\n",
    "\n",
    "Seismocardiography(SCG) is a very promising technique to measure Heart Rate (HR) and Respiratory Rate (RR) with the detector positioned above sternum. It is generally based on accelerometer and gyroscope readings or a combination of them.\n",
    "\n",
    "MuSe(Multi-Sensor miniaturized, low-power, wireless [IMU](https://en.wikipedia.org/wiki/Inertial_measurement_unit)) is an Inertial Measurement Unit (IMU) provide by [221e](https://www.221e.com). In the context of this project, It allows to record the inertial data necessary for the estimation of SCG.\n",
    "\n",
    "The dataset used (**center_sternum.txt**) provide measurments acquired on a subject who was lying supine on his left and right side, respectively. MuSe  is placed on the center of the sternum"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Libraries:\n",
    "\n",
    "The main libraries used to perform SCG are the following:\n",
    "\n",
    "1. **Pandas**: to collect the dataset as DataFrame and select the columns of interest. \n",
    "* **Numpy**: to perform operations with arrays and use some usefull tools\n",
    "* **Matplotlib**: to plot the resuls \n",
    "* **Seaborn**: to have a nice design of the plotted results \n",
    "* **Scipy**: to perform some numerical routines, such as linear algebra and statistics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "######  LIBRARIES  #######\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math \n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import linalg as la\n",
    "from scipy import fft, ifft\n",
    "from scipy.signal import welch, butter, filtfilt, find_peaks\n",
    "import pywt\n",
    "import seaborn as sns\n",
    "import matplotlib\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data preparation:\n",
    "\n",
    "In this first part the dataset is loaded as DataFrame. The columns of interest are selected to do a complete data analysis. A \"Time\" column is added. This one will be usefull in the last part of the project to understand at which time a heart beat occurs. \n",
    "\n",
    "The selected data are then plotted. These are the three components of both the Accelerometer and Gyroscope. Thanks to these plots we are able to have an opening view of how these signals look like. Moreover a very noisily area at the begin and at the end of those signals can be detected. As consequence the signals are then cutted to select just the central part. These part correspond to exactly 60 seconds of data collections. \n",
    "\n",
    "1. Load the txt file and select only the columns you are interesting in, in order to do a complete data analysis (e.g. Log Freq, AccX, ... )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###### IMPORT DATA #######\n",
    "file_name = \"center_sternum.txt\"\n",
    "\n",
    "# creation of a DataFrame containing the whole dataset\n",
    "df_sternum = pd.DataFrame(pd.read_csv(file_name, sep = \"\\t\", header = 0))\n",
    "\n",
    "# select just the column of interest\n",
    "df_sternum = df_sternum.iloc[:,[1,3,4,5,6,7,8]]\n",
    "\n",
    "# recover the samples frequency\n",
    "freq = df_sternum['Log Freq'][0]\n",
    "\n",
    "# create the time vector\n",
    "time = np.arange(0, len(df_sternum)* 1/freq, 1/freq)\n",
    "\n",
    "# create the AccX, AccY, AccZ ,GyroX, GyroY, GyroZ vectors\n",
    "accX, accY, accZ = df_sternum['AccX'][:], df_sternum['AccY'][:], df_sternum['AccZ'][:]\n",
    "gyroX,gyroY,gyroZ = df_sternum['GyroX'][:], df_sternum['GyroY'][:], df_sternum['GyroZ'][:]\n",
    "\n",
    "# insert time column\n",
    "df_sternum.insert(1, \"Time\", time)\n",
    "\n",
    "# print data\n",
    "df_sternum.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Plot selected data in function of time and choose a properly time window over which to perform the analysis. Pay attention on time rappresentation and the measurament unit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "##### PLOT OF THE DATA #####\n",
    "matplotlib.rcParams['mathtext.fontset'] = 'cm'\n",
    "matplotlib.rcParams['font.family'] = 'STIXGeneral'\n",
    "sns.set()\n",
    "# create the subplots \n",
    "figure, axis = plt.subplots(1,2, figsize = (15,5))\n",
    "\n",
    "# plot the accelerometer's data\n",
    "axis[0].plot(time,accX,'r',label = 'AccX')\n",
    "axis[0].plot(time,accY,'b',label = 'AccY')\n",
    "axis[0].plot(time,accZ,'g',label = 'AccZ')\n",
    "axis[0].set_xlabel('Time [s]')\n",
    "axis[0].set_ylabel('Acceleration [mg]')\n",
    "axis[0].set_title('ACCELEROMETER')\n",
    "axis[0].legend(loc = 1)\n",
    "\n",
    "#plot the gyroscope's data\n",
    "axis[1].plot(time,gyroX,'r',label = 'gyroX')\n",
    "axis[1].plot(time,gyroY,'b',label = 'gyroY')\n",
    "axis[1].plot(time,gyroZ,'g',label = 'gyroZ')\n",
    "axis[1].set_xlabel('Time [s]')\n",
    "axis[1].set_ylabel('Angular velocity [dps]')\n",
    "axis[1].set_title('GYROSCOPE')\n",
    "axis[1].legend(loc = 1)\n",
    "\n",
    "# create the subplots for a detail of the previous ones\n",
    "figure, axis = plt.subplots(1,2, figsize = (15,5))\n",
    "\n",
    "# plot a detail of the accelerometer plot\n",
    "axis[0].plot(time,accX,'r',label = 'AccX')\n",
    "axis[0].plot(time,accY,'b',label = 'AccY')\n",
    "axis[0].set_xlabel('Time [s]')\n",
    "axis[0].set_ylabel('Acceleration [mg]')\n",
    "axis[0].set_title('Detail of AccX and AccY')\n",
    "axis[0].set_ylim([-80,150])\n",
    "axis[0].set_xlim([10,25])\n",
    "axis[0].legend(loc = 1)\n",
    "\n",
    "# plot a detail of the gyroscope plot\n",
    "axis[1].plot(time,gyroX,'r',label = 'gyroX')\n",
    "axis[1].plot(time,gyroY,'b',label = 'gyroY')\n",
    "axis[1].plot(time,gyroZ,'g',label = 'gyroZ')\n",
    "axis[1].set_xlabel('Time [s]')\n",
    "axis[1].set_ylabel('Angular velocity [dps]')\n",
    "axis[1].set_title('GYROSCOPE')\n",
    "axis[1].set_ylim([-10,10])\n",
    "axis[1].set_xlim([10,25])\n",
    "axis[1].legend(loc = 1)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# select interval of interest to avoid the large amount of noise at the beginning and at the end of the original\n",
    "# signal\n",
    "df_sternum = df_sternum[(df_sternum['Time'] >= 10) & (df_sternum['Time'] < 70)]\n",
    "\n",
    "# update accX, accY, accZ, gyroX, gyroY, gyroZ according to the new interval of interest\n",
    "time = np.arange(0, len(df_sternum)* 1/freq, 1/freq)\n",
    "accX, accY, accZ = df_sternum['AccX'][:], df_sternum['AccY'][:], df_sternum['AccZ'][:]\n",
    "gyroX, gyroY, gyroZ = df_sternum['GyroX'][:], df_sternum['GyroY'][:], df_sternum['GyroZ'][:]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. In order to make an appropiate work, decide if take care about some particular axis or some combination of them as well as derived features for the next step of the task. Motivate your choice."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**PCA** (Principal Component Analysis) is a dimensionality reduction technique. It's used to extract relevant information in a big confusing dataset. The goal of PCA is to find a new basis to re-express a dataset in order to reveal interesting stucture.\n",
    "\n",
    "The central idea of PCA is to find out redudancy between variables and remove it as much as possibile. The main steps of PCA are the following: \n",
    "1. Compute the data mean vector from the data matrix X. \n",
    "* Subtract off mean vector from the dataset.\n",
    "* Calculate the sample covariance matrix Cx.\n",
    "* Calculate eigenvectors of matrix Cx in order to obtain the matrix P (new base).\n",
    "* Apply the change of base PX = Y. Y will be the tranformed data matrix, if digonal, is uncurrelated and so we won't have any redundacy.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**PCA for Accelerometer**\n",
    "\n",
    "In this section the PCA is used over the three components of the Accelerometer. \n",
    "\n",
    "As consequence of the results, a new base is apply to the data matrix and we reduce it from three to two dimensions. This operation allow us to keep and amount of 91% of information from the original matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# create the matrix for the PCA technique, in the rows there are the AccX, AccY, AccZ measurments, and each \n",
    "# column represents a data sample\n",
    "\n",
    "matplotlib.rcParams['mathtext.fontset'] = 'cm'\n",
    "matplotlib.rcParams['font.family'] = 'STIXGeneral'\n",
    "sns.set()\n",
    "X_acc = np.array([accX, accY, accZ])\n",
    "\n",
    "figure, axis = plt.subplots(1,3, figsize = (18,5))\n",
    "axis[0].scatter(X_acc[0,:], X_acc[1,:], alpha=0.3, color = 'b')\n",
    "axis[0].set_xlabel('AccX')\n",
    "axis[0].set_ylabel('AccY')\n",
    "axis[1].scatter(X_acc[0,:], X_acc[2,:], alpha=0.3, color = 'b')\n",
    "axis[1].set_xlabel('AccX')\n",
    "axis[1].set_ylabel('AccZ')\n",
    "axis[2].scatter(X_acc[1,:], X_acc[2,:], alpha=0.3, color = 'b')\n",
    "axis[2].set_xlabel('AccY')\n",
    "axis[2].set_ylabel('AccZ')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute the mean of X and subtract it to obtain a zero main matrix X\n",
    "X_acc = X_acc - X_acc.mean()\n",
    "\n",
    "# calculate the eigenvalues and eigenvectors of the covariance matrix and compute the covariance matrix of the new \n",
    "# matrix \n",
    "l, V = la.eig(np.cov(X_acc))\n",
    "#P = V.T\n",
    "#Cy = P.dot(np.cov(X_acc)).dot(P.T)\n",
    "Cy = np.diag(np.round(np.real(l),2))\n",
    "print(Cy, \"\\n\")\n",
    "\n",
    "\n",
    "# estimate if reduce dimensionality is convenient \n",
    "print(\"Trace of the original data matrix: \" , np.round(np.cov(X_acc).trace(),2))\n",
    "print(\"Trace of the data matrix after the changes of base: \", np.round(Cy.trace(),2), \"\\n\")\n",
    "\n",
    "print(\"Fraction of the total variability keeping only the first principal component: \", np.round(100*(Cy[0,0])/Cy.trace()),\"%\")\n",
    "print(\"Fraction of the total variability keeping only the first two principal components: \", np.round(100*(Cy[0,0]+Cy[1,1])/Cy.trace()),\"%\")\n",
    "print(\"Fraction of the total variability keeping only the last two principal components: \", np.round(100*(Cy[1,1]+Cy[2,2])/Cy.trace()),\"%\")\n",
    "\n",
    "# as consequence of the PCA technique keeping the two principal components for the Accelerometer is better\n",
    "\n",
    "P = V[:,0:2] #the eigenvectors are in the columns of V\n",
    "\n",
    "PCA_acc = P.T.dot(X_acc) # new data according to PCA result\n",
    "\n",
    "#Visualize the original data projected into the new space with the relative principal axis\n",
    "scale_factor = 0.001\n",
    "first_dim = PCA_acc[0] - PCA_acc[0].mean()\n",
    "second_dim = PCA_acc[1] - PCA_acc[1].mean()\n",
    "matplotlib.rcParams['mathtext.fontset'] = 'cm'\n",
    "matplotlib.rcParams['font.family'] = 'STIXGeneral'\n",
    "sns.set()\n",
    "plt.figure(figsize=(10,6))\n",
    "plt.scatter(first_dim, second_dim, alpha=0.3, c = 'b')\n",
    "plt.plot([0, scale_factor*l[0]*np.cov(PCA_acc)[0,0]], [0, scale_factor*l[0]*np.cov(PCA_acc)[1,0]], 'r', lw=3)\n",
    "plt.plot([0, scale_factor*l[1]*np.cov(PCA_acc)[0,1]], [0, scale_factor*l[1]*np.cov(PCA_acc)[1,1]], 'r', lw=3)\n",
    "plt.title('PCA: ACCELEROMETER')\n",
    "plt.xlabel('First dimension')\n",
    "plt.ylabel('Second dimension')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**PCA for Gyroscope**\n",
    "\n",
    "In this section the PCA is used over the three components of the Gyroscope. \n",
    "\n",
    "As consequence of the results, a new base is apply to the data matrix and we reduce it from three to two dimensions. This operation allow us to keep and amount of 96% of information from the original matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_gyro = np.array([gyroX, gyroY, gyroZ]) \n",
    "matplotlib.rcParams['mathtext.fontset'] = 'cm'\n",
    "matplotlib.rcParams['font.family'] = 'STIXGeneral'\n",
    "sns.set()\n",
    "figure, axis = plt.subplots(1,3, figsize = (18,5))\n",
    "axis[0].scatter(X_gyro[0,:], X_gyro[1,:], alpha=0.3, color = 'b')\n",
    "axis[0].set_xlabel('GyroX')\n",
    "axis[0].set_ylabel('GyroY')\n",
    "axis[1].scatter(X_gyro[0,:], X_gyro[2,:], alpha=0.3, color = 'b')\n",
    "axis[1].set_xlabel('GyroX')\n",
    "axis[1].set_ylabel('GyroZ')\n",
    "axis[2].scatter(X_gyro[1,:], X_gyro[2,:], alpha=0.3, color = 'b')\n",
    "axis[2].set_xlabel('GyroY')\n",
    "axis[2].set_ylabel('GyroZ')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#compute the mean of X and subtract it to obtain a zero main matrix X\n",
    "X_gyro = X_gyro - X_gyro.mean()\n",
    "\n",
    "# calculate the eigenvalues and eigenvectors of the covariance matrix and compute the covarinace matrix of the new \n",
    "# matrix \n",
    "l, V = la.eig(np.cov(X_gyro))\n",
    "#P = V.T\n",
    "#Cy = P.dot(np.cov(X)).dot(P.T)\n",
    "Cy = np.diag(np.round(np.real(l),2))\n",
    "print(Cy, \"\\n\")\n",
    "\n",
    "\n",
    "# estimate if reduce dimensionality is convenient \n",
    "print(\"Trace of the original data matrix: \" , np.round(np.cov(X_gyro).trace(),2))\n",
    "print(\"Trace of the data matrix after the changes of base: \", np.round(Cy.trace(),2), \"\\n\")\n",
    "\n",
    "print(\"Fraction of the total variability keeping only the first principal component: \", np.round(100*(Cy[0,0])/Cy.trace()),\"%\")\n",
    "print(\"Fraction of the total variability keeping only the first two principal components: \", np.round(100*(Cy[0,0]+Cy[1,1])/Cy.trace()),\"%\")\n",
    "print(\"Fraction of the total variability keeping only the last two principal components: \", np.round(100*(Cy[1,1]+Cy[2,2])/Cy.trace()),\"%\")\n",
    "\n",
    "# as consequence of the PCA technique keeping the two principal components for the Gyroscope is better\n",
    "P = V[:,0:2] #the eigenvectors are in the columns of V\n",
    "\n",
    "PCA_gyro = P.T.dot(X_gyro) # new data according to PCA result\n",
    "\n",
    "\n",
    "#Visualize the original data projected into the new space with the relative principal axis\n",
    "first_dim = PCA_gyro[0] - PCA_gyro[0].mean()\n",
    "second_dim = PCA_gyro[1] - PCA_gyro[1].mean()\n",
    "matplotlib.rcParams['mathtext.fontset'] = 'cm'\n",
    "matplotlib.rcParams['font.family'] = 'STIXGeneral'\n",
    "sns.set()\n",
    "plt.figure(figsize=(10,6))\n",
    "plt.scatter(first_dim, second_dim, alpha=0.3, c = 'b')\n",
    "plt.plot([0, l[0]*np.cov(PCA_gyro)[0,0]], [0, l[0]*np.cov(PCA_gyro)[1,0]], 'r', lw=2)\n",
    "plt.plot([0, l[1]*np.cov(PCA_gyro)[0,1]], [0, l[1]*np.cov(PCA_gyro)[1,1]], 'r', lw=2)\n",
    "plt.title('PCA: GYROSCOPE')\n",
    "plt.xlabel('First dimension')\n",
    "plt.ylabel('Second dimension')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Time and frequency analysis:\n",
    "\n",
    "1. Statistical analysis: provide a statistical description of the chosen dataset. Statistical descriptors includes for example mean, median, variance, standard deviation, 25th and 75th percentiles, and correlation coefficients. Investigate what could be the most interesting descriptors for this type of data, motivating the choices.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create dataframe with the component obtained from PCA\n",
    "\n",
    "A = [PCA_acc[0].reshape(len(PCA_acc[0]), 1), PCA_acc[1].reshape(len(PCA_acc[1]), 1), PCA_gyro[0].reshape(len(PCA_gyro[0]), 1), PCA_gyro[1].reshape(len(PCA_gyro[1]), 1)]\n",
    "A = np.array(A).reshape(len(PCA_acc[0]), 4)\n",
    "df_PCA = pd.DataFrame(data = A)\n",
    "df_PCA.insert(0, \"Time\", time)\n",
    "\n",
    "# compute statistics\n",
    "df_PCA = df_PCA.describe()\n",
    "df_PCA = df_PCA.rename(columns={\"Time\": \"Time [s]\", 0 : \"AccX [mg]\", 1: \"AccY [mg]\", 2: \"GyroX [rad/s]\", 3: \"GyroY [rad/s]\"})\n",
    "df_PCA.round(1)\n",
    "stat = df_PCA.iloc[:,1:].round(1) \n",
    "\n",
    "# TODO: add correlation coeffs grassie\n",
    "stat\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Fourier Analysis: Perform a frequency analysis of the data. Look at the spectrum and explain what you see. Use this step in order to properly design the filters in the following step. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_fft_values(y_values, T, N, f_s):\n",
    "    f_values = np.linspace(0.0, 1.0/(2.0*T), N//2)      \n",
    "    fft_values_ = fft(y_values)\n",
    "    fft_values = 2.0/N * np.abs(fft_values_[0:N//2])     \n",
    "    return f_values, fft_values\n",
    "\n",
    "def get_psd_values(y_values, T, N, f_s):\n",
    "    f_values, psd_values = welch(y_values, fs=f_s)\n",
    "    return f_values, psd_values\n",
    "\n",
    "N = df_sternum.shape[0]\n",
    "T = 1/freq   \n",
    "f_s = freq   \n",
    "\n",
    "f_accX, fft_accX = get_fft_values(np.array(PCA_acc[0]), T, N, f_s)\n",
    "f_accY, fft_accY  = get_fft_values(np.array(PCA_acc[1]), T, N, f_s)\n",
    "f_gyroX, fft_gyroX = get_fft_values(np.array(PCA_gyro[0]), T, N, f_s)\n",
    "f_gyroY, fft_gyroY = get_fft_values(np.array(PCA_gyro[1]), T, N, f_s)\n",
    "\n",
    "figure, axis = plt.subplots(2, 2, figsize = (15, 5))\n",
    "axis[0, 0].plot(f_accX, fft_accX)\n",
    "axis[0, 0].set_ylim([0, 2])\n",
    "axis[0, 1].plot(f_accY, fft_accY)\n",
    "axis[0, 1].set_ylim([0, 2])\n",
    "axis[1, 0].plot(f_gyroX, fft_gyroX)\n",
    "axis[1, 0].set_ylim([0, 2])\n",
    "axis[1, 1].plot(f_gyroY, fft_gyroY)\n",
    "axis[1, 1].set_ylim([0, 2])\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f_accX_psd, fft_accX_psd = get_psd_values(np.array(PCA_acc[0]), T, N, f_s)\n",
    "f_accY_psd, fft_accY_psd  = get_psd_values(np.array(PCA_acc[1]), T, N, f_s)\n",
    "f_gyroX_psd, fft_gyroX_psd = get_psd_values(np.array(PCA_gyro[0]), T, N, f_s)\n",
    "f_gyroY_psd, fft_gyroY_psd = get_psd_values(np.array(PCA_gyro[1]), T, N, f_s)\n",
    "\n",
    "figure, axis = plt.subplots(2, 2, figsize = (15, 5))\n",
    "axis[0, 0].plot(f_accX_psd, fft_accX_psd)\n",
    "#axis[0, 0].set_ylim([0, 2])\n",
    "axis[0, 1].plot(f_accY_psd, fft_accY_psd)\n",
    "#axis[0, 1].set_ylim([0, 2])\n",
    "axis[1, 0].plot(f_gyroX_psd, fft_gyroX_psd)\n",
    "#axis[1, 0].set_ylim([0, 2])\n",
    "axis[1, 1].plot(f_gyroY_psd, fft_gyroY_psd)\n",
    "#axis[1, 1].set_ylim([0, 2])\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Filter:**\n",
    "    \n",
    "Implement your own filter, trying to extrapolate heart rate signal. Hint:\n",
    "    \n",
    "    (a) Directly from Fourier Analysis, antitrasform data looking for the most interesting frequency band.\n",
    "    \n",
    "    (b) Choose the appropriate Lowpass/Bandpass/Highpass filter.\n",
    "    \n",
    "    (c) Wavelet trasform (a powerfull instrument that make a time and frequency analysis of signal).\n",
    "    \n",
    "    (d) Find another method by yourselves.\n",
    "    \n",
    "Motivate your choice.\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize\n",
    "selected = (PCA_gyro[0]-np.mean(PCA_gyro[0]))\n",
    "fs = 200\n",
    "lf = 40/60 #bmp to Hz\n",
    "hf = 120/60 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fftfilt(x,lf,hf,fs):\n",
    "    X = np.fft.rfft(x)\n",
    "    f = np.fft.rfftfreq(len(x),1/fs)\n",
    "    X_filt = np.array([X[i] if (f[i] >= lf and f[i] <= hf) else 0 for i in range(0,len(X))])\n",
    "    x_filt = np.fft.irfft(X_filt)\n",
    "    return x_filt\n",
    "\n",
    "def butterfilt(x, lf, hf, fs):\n",
    "    b,a = butter(4,[lf,hf], btype='bandpass', fs=fs)\n",
    "    x_filt = filtfilt(b,a, x)  \n",
    "    return x_filt \n",
    "\n",
    "def wavelet(x):\n",
    "    # 1. Decompose the signal using the DWT.\n",
    "    # 2. Filter the signal in the wavelet space using thresholding.\n",
    "    # 3. Invert the filtered signal to reconstruct the original, now filtered signal, using the inverse DWT.\n",
    "    \n",
    "    # cut frequencies \n",
    "    \n",
    "    # DWT\n",
    "    cA, cD = pywt.dwt(x,'sym4') \n",
    "\n",
    "    # Compute threshold something like this.  You need an estimate of the noise sigma.\n",
    "    threshold=1*math.sqrt(2*math.log2(x.size))\n",
    "\n",
    "    # Apply the threshold.\n",
    "    cA_threshold = pywt.threshold(cA, threshold, 'soft')\n",
    "    cD_threshold = pywt.threshold(cD, threshold, 'soft')\n",
    "    \n",
    "    # IDWT\n",
    "    renc = pywt.idwt(cA_threshold, cD_threshold, 'sym4'); \n",
    "    \n",
    "    return renc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Computation\n",
    "sig_filt_fft = fftfilt(selected,lf,hf,fs)\n",
    "sig_filt_butter = butterfilt(selected,lf,hf,fs)\n",
    "sig_filt_wavelet = wavelet(selected)\n",
    "\n",
    "# Plot\n",
    "figure, axis = plt.subplots(3, 1, figsize = (20, 15))\n",
    "\n",
    "axis[0].plot(time, selected, 'green')\n",
    "axis[0].plot(time, sig_filt_fft, 'red')\n",
    "axis[0].set_xlim([30,40])\n",
    "\n",
    "axis[1].plot(time, selected, 'green')\n",
    "axis[1].plot(time, sig_filt_butter, 'red')\n",
    "axis[1].set_xlim([30,40])\n",
    "\n",
    "axis[2].plot(time, sig_filt_wavelet, 'red')\n",
    "axis[2].plot(time, selected, 'green')\n",
    "axis[2].set_xlim([30,40])\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show choosen filter\n",
    "figure, axis = plt.subplots(3, 1, figsize = (20, 15))\n",
    "\n",
    "axis[0].plot(time, sig_filt_wavelet, 'black')\n",
    "axis[0].set_xlim([0,1])\n",
    "\n",
    "axis[1].plot(time, sig_filt_wavelet, 'black')\n",
    "axis[1].set_xlim([32,36])\n",
    "\n",
    "axis[2].plot(time, sig_filt_wavelet, 'black')\n",
    "axis[2].set_xlim([0,60])\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Metrics:**\n",
    "\n",
    "1. Heart Beat Per Minute(BPM): extrapolate BPM, make an histogram of the result. Does it follow a partiular distribution? \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create histogram \n",
    "# FIND ALL PEAKS ASSOCIATI AL SECONDO, PER TROVARE IL PASSO \n",
    "\n",
    "peak_times = []\n",
    "peak_time = 0\n",
    "\n",
    "for i in range(1, len(sig_filt_wavelet)):     \n",
    "    if abs(sig_filt_wavelet[i]) > 0.:\n",
    "        peak_time = i/200\n",
    "        peak_time = round(peak_time % 1, 1)\n",
    "        peak_times.append(peak_time)\n",
    "    \n",
    "print(peak_times)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import statistics\n",
    "\n",
    "print(statistics.mean(peak_times)) #BPM = 60 / mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#fare hist e gaussiana calcolare mean e variance\n",
    "# BPM = mean +- varianze\n",
    "#PER MR TAMBURINO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#cerco i picchi (battiti) \n",
    "peaks_fft,_ = find_peaks(sig_filt_fft, height=0.2, threshold=None, distance=fs/hf, prominence=0.4, width=None, wlen=None, rel_height=0.5, plateau_size=None)\n",
    "peaks_butt,_ = find_peaks(sig_filt_butter, height=0.2, threshold=None, distance=fs/hf, prominence=0.4, width=None, wlen=None, rel_height=0.5, plateau_size=None)\n",
    "peaks_wavelet,_ = find_peaks(sig_filt_wavelet, height=0.2, threshold=None, distance=fs/hf, prominence=0.4, width=None, wlen=None, rel_height=0.5, plateau_size=None)\n",
    "print(\"mean BPM with FFT filt= \",len(peaks_fft)*60/(len(sig_filt_fft)/fs))\n",
    "print(\"mean BPM with butterworth filt= \",len(peaks_butt)*60/(len(sig_filt_butter)/fs))\n",
    "print(\"mean BPM with wavelet filt= \",len(peaks_wavelet)*60/(len(sig_filt_wavelet)/fs))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "array = np.full(len(peaks_wavelet), 2)\n",
    "\n",
    "plt.figure(figsize=(20, 10))\n",
    "plt.plot(time, sig_filt_wavelet, 'black')\n",
    "plt.plot(peaks_wavelet/200, array, 'o')\n",
    "plt.xlim(9,20)\n",
    "\n",
    "# TODO: DA FARE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Heart Rate Variability(HRV): extrapolate HRV, explain why this parameter is important, and plot the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Optional Algorithm:** \n",
    "\n",
    "Elaborate a simple algorithm to extrapolate heart beat even when filter failed (e.g. look at particular threshold...).  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Conclusion:**\n",
    "\n",
    "Summarise the obtained results, in particular making a comparison between the two files analysed. Highlight limitation and critical issues encountered during the work, motivating the most relevant contribution given by your solution.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
